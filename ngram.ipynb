{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b7019e0b-b72d-4495-ace6-a59340bffa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a2aa2c-89e0-406b-a6cb-fb32712f40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = open('names.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835a506d-8cbd-4aa7-8db7-02504eab5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(n, names_with_tokens):\n",
    "    ngrams = []\n",
    "    for w in names_with_tokens:\n",
    "        for zps in zip(*(w[i:] for i in range(n))):\n",
    "            ngrams.append(''.join([*zps]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcdbe8b4-9eca-4099-9a96-0d1ed01d6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set(''.join(names))\n",
    "chars.add('.')\n",
    "n_chars = len(chars)\n",
    "\n",
    "stoi = {s:i for i,s in enumerate(sorted(chars))}\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8167239e-a6e7-4284-8327-16092619f78d",
   "metadata": {},
   "source": [
    "### create training set of ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe72ec-2dfe-48fc-82b9-3dfa250b99e8",
   "metadata": {},
   "source": [
    "#### trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6abaa9b2-e525-47c1-860b-1c0b09166fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d6e363b7-fcf2-4d68-8e18-344628b32b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_with_tokens = ['.'+name+'.' for name in names]\n",
    "xs, ys = [], []\n",
    "\n",
    "for tg in generate_ngrams(window_size, names_with_tokens):\n",
    "    c1,c2,c3 = tg\n",
    "    xs.append([stoi[c1], stoi[c2]])\n",
    "    ys.append(stoi[c3])\n",
    "    \n",
    "x = torch.tensor(xs)\n",
    "y = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "df29f2dc-4f1f-4e82-bed2-d863e3c609af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "def forward(W):\n",
    "    logits = torch.zeros((batch_size, n_chars))\n",
    "    \n",
    "    batch_ix = torch.randint(high=xenc.shape[0]-1, size=(batch_size,))\n",
    "    \n",
    "    batch = xenc[batch_ix]\n",
    "    for ineuron in range(window_size - 1):\n",
    "        logits += batch[:, ineuron, :] @ W[ineuron]\n",
    "    probs = logits.softmax(1)\n",
    "    preds = probs[torch.arange(batch_size), y[batch_ix]]\n",
    "    loss = -preds.log().mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "0ea6dd99-40b0-48ae-8d55-c99a43c2b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = torch.Generator().manual_seed(5)\n",
    "\n",
    "W = torch.randn((window_size-1, n_chars, n_chars), requires_grad=True, generator=G)\n",
    "n_epochs = 5000\n",
    "\n",
    "for t in range(n_epochs): \n",
    "    loss = forward(W)\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -10*math.exp(-t/n_epochs) * W.grad\n",
    "loss = forward(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "4ccd39af-05dc-41a7-982f-6d426d7a961c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.216637134552002"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d14d0-88fa-4568-a58a-18778e1f6a5a",
   "metadata": {},
   "source": [
    "What should the loss be?\n",
    "\n",
    "- Completely random gives -log(1/27) = 3.296 which is also equal to forward( torch.zeros(W.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bfd97-2bbe-4bac-89aa-4979ef16f760",
   "metadata": {},
   "source": [
    "## Predict a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "eba07ec4-1a62-4370-b37a-0ad97f878311",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letters = torch.zeros(n_chars)\n",
    "for n in names:\n",
    "    ix = stoi[n[0]]\n",
    "    first_letters[ix] += 1\n",
    "first_letter_probs = first_letters/first_letters.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "0e37facf-0a53-4a95-a2b9-29cf3234d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_name():\n",
    "    # select a starting letter according to the distribution of starting letters\n",
    "    name_start = '.'+itos[torch.multinomial(first_letter_probs, 1).item()]\n",
    "\n",
    "    predicted_name = ''\n",
    "    predicted_name += name_start\n",
    "    while True:\n",
    "        inp_ix = [stoi[i] for i in predicted_name[-2:]]\n",
    "        inp_enc = F.one_hot(torch.tensor(inp_ix), n_chars).float()\n",
    "\n",
    "        logits = torch.zeros((1, n_chars))\n",
    "        for ineuron in range(window_size-1):\n",
    "            logits += inp_enc[ineuron, :] @ W[ineuron]\n",
    "        probs = logits.softmax(1)\n",
    "        prediction = itos[torch.multinomial(probs, 1).item()]\n",
    "        predicted_name += prediction\n",
    "        if prediction == '.':\n",
    "            break\n",
    "        \n",
    "    return predicted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "2dfd967b-10a0-4c4c-8ce5-8c897899cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".kianwacheinalaeng.\n",
      ".aleynne.\n",
      ".ieash.\n",
      ".dena.\n",
      ".masslia.\n",
      ".masyn.\n",
      ".oa.\n",
      ".zavenna.\n",
      ".latli.\n",
      ".delyn.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    p = predict_name()\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "4acbabdd-9ecb-43c8-934d-bee8625d4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some nice ones:\n",
    "\n",
    "# sahanniah, catmarisona, moriganna, swadish, zaria, nuaster, nahrienela\n",
    "\n",
    "# some existing words\n",
    "# dan, mary, ass, die"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
